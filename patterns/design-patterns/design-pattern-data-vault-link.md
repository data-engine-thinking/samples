---
uid: design-pattern-data-vault-link
---

# Design Pattern - Data Vault - Link

## Purpose

This design pattern describes how to define, and load data into, Data Vault Link style tables.

## Motivation

A Link table in Data Vault is the physical implementation of a Natural Business Relationship. A Link uniquely identifies a relationship between Core Business Concepts (Hub tables in Data Vault).

The Link concept in Data Vault provides the flexibility of this data Modeling approach. Links are sets of (hub) keys that indicate that a relationship between those Hubs has existed at some point in time.

A Link table is similar in concept to the Hub table, but only stores key pairs.

Even though the Data Vault concept allows for adding attributes in the Link table it is strongly recommended (for flexibility reasons) to only store the generated hash key (meaningless key), the Hub surrogate hash keys and the timestamp information. Doing this will ensure compatibility with both stationary facts (time dependent facts such as balances) and pure transactions.

## Applicability

This pattern is only applicable for loading processes from the Landing Area into the Integration Area and from the Integration Area to the Interpretation Area. The pattern varies slightly for the type of Link table specified (such as Transactional Link, Same-As Link, Hierarchical Link or Low-Value Links) or whether it contains a degenerate attribute. In most cases the Link table will contain the default attributes (Link Key, Hub Keys and metadata attributes) but in the case of a pure transactional Link table it can contain the transaction attributes as well.

## Structure

The data logistics process can be described as an 'insert only' set of the unique combination of Data Warehouse keys. Depending on the type of source table, the process will do the following:

Source Area to Integration Area: the process executes a SELECT DISTINCT query on business keys and performs key lookups (outer join) on the corresponding Hub tables to obtain the Hub Data Warehouse keys. The resulting key combination is then verified using a key lookup against the target Link table to verify if that specific combination of Data Warehouse keys already exists. If it exists, the row can be discarded, if not it can be inserted.

Integration Area to Interpretation Area: the process executes a SELECT DISTINCT query on Data Warehouse keys (likely after combining multiple tables first) and performs a key lookup against the target Link table to verify if that specific combination of Data Warehouse keys already exists. If it exists, the row can be discarded, if not it can be inserted.
The maintenance of the Interpretation Area can also be done as part of an (external) process or through Master Data Management. In this context, Link tables between Integration and Interpretation Area tables are very similar to cross-referencing tables.

The following diagram displays the data logistics process for Link tables;
Business Insights > Design Pattern 010 - Data Vault - Loading Link tables > image2015-4-29 16:24:14.png

In a pure relational Link it is required that a dummy key is available in each corresponding Link-Satellite to complete the timelines. This is handled as part of the Link-Satellite processing as a Link can contain multiple Link-Satellites. Dummy records are only required to be inserted for each driving key as a view in time across the driving key is ultimately required. Inserting a dummy record for every Link key will cause issues in the timeline. This is explained in more detail in the Link-Satellite Design Pattern.

## Implementation guidelines

Use a single data logistics process, module or mapping to load the Link table, thus improving flexibility in processing. Every data logistics process should have a distinct function.

Multiple passes of the same source table or file are usually required. The first pass will insert new keys in the Link table; the other passes are needed to populate the Link Satellite tables (if any).

By default, create a sequence / meaningless key for each unique key combination in a Link table.
Link tables can be seen as the relationship equivalent of Hub tables; only distinct new key pairs are inserted.
Inscription timestamp is copied from the Landing Area tables and not generated by the data logistics process.

### Optional attributes

The following attributes are commonly included in Link tables but are technically optional:

- **Record Source**: Can be derived from the Audit Trail Id via the control framework. Including it as a separate column is a convenience for querying but introduces redundancy.
- **Inscription Timestamp**: While recommended for auditability, this can be derived from the control framework if the Audit Trail Id is present.

The Audit Trail Id provides the essential link to the control framework, from which all process metadata (including Record Source and timing information) can be obtained.

The logic to create the initial (dummy) Satellite record can both be implemented as part of the Link data logistics process, as a separate data logistics process which queries all keys that have no corresponding dummy or as part of the Link-Satellite data logistics process. This depends on the capabilities of the data logistics software since not all are able to provide and reuse sequence generators or able to write to multiple targets in one process. 

The default and arguably most flexible way is to incorporate this concept as part of the Link-Satellite data logistics since it does not require rework when additional Link-Satellites are associated with the Link. This means that each Link-Satellite data logistics must perform a check if a dummy record exists before starting the standard process (and be able to roll back the dummy records if required).

Depending on how the Link table is modelled (what kind of relationship it manages) the Link table may contains a relationship type attribute. If a link table contains multiple, or changing, relationships (types) this attributes is moved to the Link-Satellite table.
Ending /closing relationships is always done in the Link-Satellite table, typically using a separate data logistics process.

## Considerations and consequences

Multiple passes on source data is likely to be required. In extreme cases a single source table might be used (branch out) to Hubs, Satellites, Links and Link Satellites.

This type of data logistics process is to be used for loading all link tables in both the Integration Area as well as the Interpretation Area. This is because the Link table is also used to relate raw (Integration Area) data and cleansed (Interpretation Area) data together.

Link cardinality and driving keys affect timeline handling; ensure Link-Satellite design supports history correctly.

Including attributes in Links reduces flexibility; prefer attribute storage in Link-Satellites unless truly degenerate.

Parallel loads from multiple sources require duplicate prevention (hash keys, unique constraints) to avoid double inserts.

## Related patterns

* [Design Pattern - Generic - Using Start, Process and End Dates](xref:design-pattern-generic-managing-multi-temporality).
* [Design Pattern - Data Vault - Hub tables](xref:design-pattern-data-vault-hub).

